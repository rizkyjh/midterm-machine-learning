{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syyZJ02OMrjJ",
        "outputId": "0b17ce1b-31de-4923-dd66-5aa0e234634e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loading train_transaction.csv... (This might take 1-2 minutes)\n",
            "Loading test_transaction.csv...\n",
            "SUCCESS! Data loaded.\n",
            "Train shape: (590540, 394)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 1. Mount your Google Drive\n",
        "# When you run this, click the link that pops up and \"Allow\" access.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Point to your specific folder\n",
        "# Based on your screenshot: My Drive -> midterm -> Fraud Transaction\n",
        "folder_path = '/content/drive/MyDrive/midterm/Fraud Transaction'\n",
        "\n",
        "# 3. Load the data using Pandas\n",
        "# We use Pandas instead of Polars because it works better with the Machine Learning code I gave you.\n",
        "print(\"Loading train_transaction.csv... (This might take 1-2 minutes)\")\n",
        "df_train = pd.read_csv(os.path.join(folder_path, 'train_transaction.csv'))\n",
        "\n",
        "print(\"Loading test_transaction.csv...\")\n",
        "df_test = pd.read_csv(os.path.join(folder_path, 'test_transaction.csv'))\n",
        "\n",
        "print(\"SUCCESS! Data loaded.\")\n",
        "print(f\"Train shape: {df_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "print(\"Starting Preprocessing...\")\n",
        "\n",
        "# 1. Memory Saving: Drop columns with > 70% missing values\n",
        "missing_percent = df_train.isnull().mean()\n",
        "drop_cols = missing_percent[missing_percent > 0.7].index\n",
        "df_train = df_train.drop(columns=drop_cols)\n",
        "df_test = df_test.drop(columns=drop_cols)\n",
        "\n",
        "# 2. Fill Missing Values\n",
        "for col in df_train.columns:\n",
        "    if df_train[col].dtype == 'object':\n",
        "        df_train[col] = df_train[col].fillna(\"Unknown\")\n",
        "        if col in df_test.columns:\n",
        "            df_test[col] = df_test[col].fillna(\"Unknown\")\n",
        "    else:\n",
        "        df_train[col] = df_train[col].fillna(0)\n",
        "        if col in df_test.columns:\n",
        "            df_test[col] = df_test[col].fillna(0)\n",
        "\n",
        "# 3. Encode Text to Numbers\n",
        "cat_cols = df_train.select_dtypes(include=['object']).columns\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    # Combine to"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzsSGZp5NDk0",
        "outputId": "1c9f875e-e96e-494c-e6bf-8977bd49d590"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Preprocessing...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"Starting Preprocessing... (Please wait)\")\n",
        "\n",
        "# 1. Memory Saving: Drop columns with > 70% missing values\n",
        "# We use the dataframes df_train and df_test loaded in Step 1\n",
        "missing_percent = df_train.isnull().mean()\n",
        "drop_cols = missing_percent[missing_percent > 0.7].index\n",
        "df_train = df_train.drop(columns=drop_cols)\n",
        "df_test = df_test.drop(columns=drop_cols)\n",
        "\n",
        "# 2. Fill Missing Values\n",
        "for col in df_train.columns:\n",
        "    # Fill text columns with \"Unknown\"\n",
        "    if df_train[col].dtype == 'object':\n",
        "        df_train[col] = df_train[col].fillna(\"Unknown\")\n",
        "        if col in df_test.columns:\n",
        "            df_test[col] = df_test[col].fillna(\"Unknown\")\n",
        "    # Fill number columns with 0\n",
        "    else:\n",
        "        df_train[col] = df_train[col].fillna(0)\n",
        "        if col in df_test.columns:\n",
        "            df_test[col] = df_test[col].fillna(0)\n",
        "\n",
        "# 3. Encode Text to Numbers\n",
        "cat_cols = df_train.select_dtypes(include=['object']).columns\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    # Combine to ensure all categories are known\n",
        "    combined = pd.concat([df_train[col], df_test[col]], axis=0).astype(str)\n",
        "    le.fit(combined)\n",
        "    df_train[col] = le.transform(df_train[col].astype(str))\n",
        "    df_test[col] = le.transform(df_test[col].astype(str))\n",
        "\n",
        "# 4. Define Features (X) and Target (y)\n",
        "X = df_train.drop(columns=['isFraud', 'TransactionID', 'TransactionDT'])\n",
        "y = df_train['isFraud']\n",
        "\n",
        "# Prepare Test Data for final submission\n",
        "test_ids = df_test['TransactionID']\n",
        "X_final_test = df_test.drop(columns=['TransactionID', 'TransactionDT'])\n",
        "# Ensure columns match exactly\n",
        "X_final_test = X_final_test[X.columns]\n",
        "\n",
        "# 5. Scale Data (Required for Deep Learning)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_final_test = scaler.transform(X_final_test)\n",
        "\n",
        "# 6. Split Train/Validation\n",
        "# THIS is where X_train is created!\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(\"Preprocessing Complete. NOW you can run Step 3.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCWSxIdrNsTF",
        "outputId": "2f211542-79bc-42d5-cc32-811fed021da7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Preprocessing... (Please wait)\n",
            "Preprocessing Complete. NOW you can run Step 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# --- Model 1: Traditional ML (Logistic Regression) ---\n",
        "# class_weight='balanced' fixes the fraud imbalance issue\n",
        "print(\"Training Logistic Regression...\")\n",
        "model_lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate LR\n",
        "prob_lr = model_lr.predict_proba(X_val)[:, 1]\n",
        "print(f\"Logistic Regression AUC Score: {roc_auc_score(y_val, prob_lr):.4f}\")\n",
        "\n",
        "# --- Model 2: Deep Learning (Neural Network) ---\n",
        "print(\"Training Neural Network (MLP)...\")\n",
        "# Input -> 64 neurons -> 32 neurons -> Output\n",
        "model_dl = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', max_iter=200, random_state=42)\n",
        "model_dl.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate DL\n",
        "prob_dl = model_dl.predict_proba(X_val)[:, 1]\n",
        "print(f\"Neural Network AUC Score: {roc_auc_score(y_val, prob_dl):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f8TtVq9NHWB",
        "outputId": "d7d68340-10c0-43fe-f471-c1650abc9be5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Logistic Regression AUC Score: 0.8373\n",
            "Training Neural Network (MLP)...\n",
            "Neural Network AUC Score: 0.9110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating submission.csv...\")\n",
        "\n",
        "# We use the Logistic Regression model for the final file\n",
        "# (It handles the imbalance explicitly and is safer for this dataset)\n",
        "final_probs = model_lr.predict_proba(X_final_test)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'TransactionID': test_ids,\n",
        "    'isFraud': final_probs\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"DONE! 'submission.csv' has been created.\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7r8GB-rNPHs",
        "outputId": "b2a42ca8-e3c0-4cae-c4a7-1648ec06e5d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating submission.csv...\n",
            "DONE! 'submission.csv' has been created.\n",
            "   TransactionID   isFraud\n",
            "0        3663549  0.124887\n",
            "1        3663550  0.357019\n",
            "2        3663551  0.459140\n",
            "3        3663552  0.091072\n",
            "4        3663553  0.119322\n"
          ]
        }
      ]
    }
  ]
}